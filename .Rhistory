<<<<<<< HEAD
sql_part3 = paste(sql_part2, ".results.", sep = '')
sql       = paste(sql_part3, cohortTable, sep = '')
# Delete table if it already exists, perhaps from a partial execution of the script.
# Commented out, because new users likely won't already have this table.
# TODO: paste(DB, ".dbo", sep='')
sql_part1 = "drop table "
sql_part2 = paste(sql_part1, DB, sep='')
sql_part3 = paste(sql_part2, ".results.", sep = '')
sql       = paste(sql_part3, cohortTable, sep = '')
sql
# Run processing sexdiff_cohort_reference_ver5.sql script
sql <- SqlRender::loadRenderTranslateSql(sqlFilename = "sexdiff_cohort_reference_ver5.sql",
packageName = "characterizationPaperPackage",
dbms = attr(conn, "dbms"))
sql
DatabaseConnector::executeSql(conn, sql)
# Run processing sexdiff_cohort_reference_ver5.sql script
sql <- SqlRender::loadRenderTranslateSql(sqlFilename = "sexdiff_cohort_reference_ver5.sql",
packageName = "characterizationPaperPackage",
dbms = attr(conn, "dbms"))
DatabaseConnector::executeSql(conn, sql)
DatabaseConnector::executeSql(conn, sql)
sql
write.table(sql, file="sql.txt", row.names=FALSE, col.names=FALSE)
disconnect(connection = conn)
detach("package:characterizationPaperPackage", unload = TRUE)
library(characterizationPaperPackage)
# Load the package
library(characterizationPaperPackage)
library(reticulate)
# Parameters [loaded from credentials.csv, which is not uploaded to Github!]
CREDENTIALS  <- 'C:\\Users\\tonys\\Documents\\Research\\csv\\credentials.csv' # login credentials
private.data = read.csv(CREDENTIALS, fileEncoding = 'UTF-8-BOM')
PYTHON_PATH  <- 'C:\\Users\\tonys\\AppData\\Local\\Programs\\Python\\Python39'
PACKAGE_PATH <- 'c:/Users/tonys/Research/characterizationPaperPackage/'
DB           <- private.data$db
cdmDatabaseSchema    <- paste(DB, ".dbo", sep='')     # eg: "ohdsi_cumc_2021q1r2.dbo"
cohortDatabaseSchema <- paste(DB, ".results", sep='') # eg: "ohdsi_cumc_2021q1r2.results"
vocabularyDatabaseSchema <- cdmDatabaseSchema
cohortTable <- "cohort_characterization"              # this is the name of the output table
# Optional: specify where the temporary files will be created:
options(andromedaTempFolder = file.path(path, "andromedaTemp"))
# Details for connecting to the server:
connectionDetails <- DatabaseConnector::createConnectionDetails(dbms = private.data$dbms,
server = private.data$server,
user = private.data$user,
password = private.data$password,
)
# For Oracle: define a schema that can be used to emulate temp tables:
oracleTempSchema <- NULL
# Start connection
conn <- DatabaseConnector::connect(connectionDetails)
# Run processing sexdiff_cohort_reference_ver5.sql script
sql <- SqlRender::loadRenderTranslateSql(sqlFilename = "sexdiff_cohort_reference_ver5.sql",
packageName = "characterizationPaperPackage",
dbms = attr(conn, "dbms"))
sql
write.table(sql, sql.txt)
write.table(sql, sql.txt)
write.table(sql, 'sql.txt')
DatabaseConnector::executeSql(conn, sql)
# Run processing sexdiff_cohort_reference_ver5.sql script
sql <- SqlRender::loadRenderTranslateSql(sqlFilename = "sexdiff_cohort_reference_ver5.sql",
packageName = "characterizationPaperPackage",
dbms = attr(conn, "dbms"))
DatabaseConnector::executeSql(conn, sql)
library(characterizationPaperPackage)
=======
>>>>>>> 544e86dbbbf7934179a26cce5a499e12485283e4
# Parameters [loaded from credentials.csv, which is not uploaded to Github!]
CREDENTIALS  <- 'C:\\Users\\tonys\\Documents\\Research\\csv\\credentials.csv' # login credentials
private.data = read.csv(CREDENTIALS, fileEncoding = 'UTF-8-BOM')
PYTHON_PATH  <- 'C:\\Users\\tonys\\AppData\\Local\\Programs\\Python\\Python39'
PACKAGE_PATH <- 'c:/Users/tonys/Research/characterizationPaperPackage/'
DB           <- private.data$db
cdmDatabaseSchema    <- paste(DB, ".dbo", sep='')     # eg: "ohdsi_cumc_2021q1r2.dbo"
cohortDatabaseSchema <- paste(DB, ".results", sep='') # eg: "ohdsi_cumc_2021q1r2.results"
vocabularyDatabaseSchema <- cdmDatabaseSchema
cohortTable <- "cohort_characterization"              # this is the name of the output table
# Optional: specify where the temporary files will be created:
options(andromedaTempFolder = file.path(path, "andromedaTemp"))
# Details for connecting to the server:
connectionDetails <- DatabaseConnector::createConnectionDetails(dbms = private.data$dbms,
server = private.data$server,
user = private.data$user,
password = private.data$password,
)
# For Oracle: define a schema that can be used to emulate temp tables:
oracleTempSchema <- NULL
# Start connection
conn <- DatabaseConnector::connect(connectionDetails)
# Instantiate cohorts:
pathToCsv <- system.file("settings", "CohortsToCreateFinal.csv", package = "characterizationPaperPackage")
cohortsToCreate <- readr::read_csv(pathToCsv, col_types = readr::cols())
# Run processing sexdiff_cohort_reference_ver5.sql script
sql <- SqlRender::loadRenderTranslateSql(sqlFilename = "sexdiff_cohort_reference_ver5.sql",
packageName = "characterizationPaperPackage",
dbms = attr(conn, "dbms"))
write.csv(sql, 'sql.txt')
DatabaseConnector::executeSql(conn, sql)
use_python(PYTHON_PATH) # Python interpreter specified in parameters
# https://community.rstudio.com/t/rpytools-error-recurring-with-package-reticulate/66625
sys <- import("sys", convert = TRUE) # Fixes run-time warning and error?
py_run_file('settings.py')
use_python(PYTHON_PATH) # Python interpreter specified in parameters
# https://community.rstudio.com/t/rpytools-error-recurring-with-package-reticulate/66625
sys <- import("sys", convert = TRUE) # Fixes run-time warning and error?
py_run_file('settings.py')
use_python(PYTHON_PATH) # Python interpreter specified in parameters
# https://community.rstudio.com/t/rpytools-error-recurring-with-package-reticulate/66625
sys <- import("sys", convert = TRUE) # Fixes run-time warning and error?
py_run_file('inst/py/settings.py')
detach("package:characterizationPaperPackage", unload = TRUE)
library(characterizationPaperPackage)
# Load the package
library(characterizationPaperPackage)
library(reticulate)
# Parameters [loaded from credentials.csv, which is not uploaded to Github!]
CREDENTIALS  <- 'C:\\Users\\tonys\\Documents\\Research\\csv\\credentials.csv' # login credentials
private.data = read.csv(CREDENTIALS, fileEncoding = 'UTF-8-BOM')
PYTHON_PATH  <- 'C:\\Users\\tonys\\AppData\\Local\\Programs\\Python\\Python39'
PACKAGE_PATH <- 'c:/Users/tonys/Research/characterizationPaperPackage/'
DB           <- private.data$db
cdmDatabaseSchema    <- paste(DB, ".dbo", sep='')     # eg: "ohdsi_cumc_2021q1r2.dbo"
cohortDatabaseSchema <- paste(DB, ".results", sep='') # eg: "ohdsi_cumc_2021q1r2.results"
vocabularyDatabaseSchema <- cdmDatabaseSchema
cohortTable <- "cohort_characterization"              # this is the name of the output table
# Optional: specify where the temporary files will be created:
options(andromedaTempFolder = file.path(path, "andromedaTemp"))
# Details for connecting to the server:
connectionDetails <- DatabaseConnector::createConnectionDetails(dbms = private.data$dbms,
server = private.data$server,
user = private.data$user,
password = private.data$password,
)
# For Oracle: define a schema that can be used to emulate temp tables:
oracleTempSchema <- NULL
# Start connection
conn <- DatabaseConnector::connect(connectionDetails)
use_python(PYTHON_PATH) # Python interpreter specified in parameters
# https://community.rstudio.com/t/rpytools-error-recurring-with-package-reticulate/66625
sys <- import("sys", convert = TRUE) # Fixes run-time warning and error?
py_run_file('inst/py/settings.py')
py_run_file('creating_summaries.py')
# Load the package
library(characterizationPaperPackage)
# Parameters [loaded from credentials.csv, which is not uploaded to Github!]
CREDENTIALS  <- 'C:\\Users\\tonys\\Documents\\Research\\csv\\credentials.csv' # login credentials
private.data = read.csv(CREDENTIALS, fileEncoding = 'UTF-8-BOM')
PYTHON_PATH  <- 'C:\\Users\\tonys\\AppData\\Local\\Programs\\Python\\Python39'
PACKAGE_PATH <- 'c:/Users/tonys/Research/characterizationPaperPackage/'
DB           <- private.data$db
# You do not have to change the below [but you can]
cdmDatabaseSchema    <- paste(DB, ".dbo", sep='')     # eg: "ohdsi_cumc_2021q1r2.dbo"
cohortDatabaseSchema <- paste(DB, ".results", sep='') # eg: "ohdsi_cumc_2021q1r2.results"
vocabularyDatabaseSchema <- cdmDatabaseSchema
cohortTable <- "cohort_characterization"              # this is the name of the output table
# Optional: specify where the temporary files will be created:
options(andromedaTempFolder = file.path(path, "andromedaTemp"))
# Details for connecting to the server:
connectionDetails <- DatabaseConnector::createConnectionDetails(dbms = private.data$dbms,
server = private.data$server,
user = private.data$user,
password = private.data$password,
)
# For Oracle: define a schema that can be used to emulate temp tables:
oracleTempSchema <- NULL
# Start connection
conn <- DatabaseConnector::connect(connectionDetails)
# Run processing for all_condition_occurrence_summary.sql script
sql <- SqlRender::loadRenderTranslateSql(sqlFilename = "all_condition_occurrence_summary",
packageName = "characterizationPaperPackage",
dbms = attr(conn, "dbms"))
# Run processing sexdiff_cohort_reference_ver5.sql script
sql <- SqlRender::loadRenderTranslateSql(sqlFilename = "sexdiff_cohort_reference_ver5.sql",
packageName = "characterizationPaperPackage",
dbms = attr(conn, "dbms"))
# Run processing for all_condition_occurrence_summary.sql script
sql <- SqlRender::loadRenderTranslateSql(sqlFilename = "all_condition_occurrence_summary.sql",
packageName = "characterizationPaperPackage",
dbms = attr(conn, "dbms"))
DatabaseConnector::executeSql(conn, sql)
py_run_file('generating_prevalence_graphs.py')
use_python(PYTHON_PATH) # Python interpreter specified in parameters
# Load the package
library(characterizationPaperPackage)
# Parameters [loaded from credentials.csv, which is not uploaded to Github!]
CREDENTIALS  <- 'C:\\Users\\tonys\\Documents\\Research\\csv\\credentials.csv' # login credentials
library(characterizationPaperPackage)
private.data = read.csv(CREDENTIALS, fileEncoding = 'UTF-8-BOM')
PYTHON_PATH  <- 'C:\\Users\\tonys\\AppData\\Local\\Programs\\Python\\Python39'
PACKAGE_PATH <- 'c:/Users/tonys/Research/characterizationPaperPackage/'
DB           <- private.data$db
# You do not have to change the below [but you can]
cdmDatabaseSchema    <- paste(DB, ".dbo", sep='')     # eg: "ohdsi_cumc_2021q1r2.dbo"
cohortDatabaseSchema <- paste(DB, ".results", sep='') # eg: "ohdsi_cumc_2021q1r2.results"
vocabularyDatabaseSchema <- cdmDatabaseSchema
cohortTable <- "cohort_characterization"              # this is the name of the output table
# Optional: specify where the temporary files will be created:
options(andromedaTempFolder = file.path(path, "andromedaTemp"))
# Details for connecting to the server:
connectionDetails <- DatabaseConnector::createConnectionDetails(dbms = private.data$dbms,
server = private.data$server,
user = private.data$user,
password = private.data$password,
)
# For Oracle: define a schema that can be used to emulate temp tables:
oracleTempSchema <- NULL
# Start connection
conn <- DatabaseConnector::connect(connectionDetails)
use_python(PYTHON_PATH) # Python interpreter specified in parameters
# https://community.rstudio.com/t/rpytools-error-recurring-with-package-reticulate/66625
# If it does throw the rpytools error, it's just a runtime error that doesn't actually
# Inhibit the scripts.
sys <- import("sys", convert = TRUE) # Fixes run-time warning and error?
# Load the package
library(characterizationPaperPackage)
py_run_file('inst/py/settings.py')
disconnect(connection = )
disconnect(connection = conn)
# Load the package
library(characterizationPaperPackage)
library(characterizationPaperPackage)
<<<<<<< Updated upstream
# Parameters [loaded from credentials.csv, which is not uploaded to Github!]
CREDENTIALS  <- 'C:\\Users\\tonys\\Documents\\Research\\csv\\credentials.csv' # login credentials
private.data = read.csv(CREDENTIALS, fileEncoding = 'UTF-8-BOM')
PYTHON_PATH  <- 'C:\\Users\\tonys\\AppData\\Local\\Programs\\Python\\Python39'
PACKAGE_PATH <- 'c:/Users/tonys/Research/characterizationPaperPackage/'
DB           <- private.data$db
# You do not have to change the below [but you can]
cdmDatabaseSchema    <- paste(DB, ".dbo", sep='')     # eg: "ohdsi_cumc_2021q1r2.dbo"
cohortDatabaseSchema <- paste(DB, ".results", sep='') # eg: "ohdsi_cumc_2021q1r2.results"
vocabularyDatabaseSchema <- cdmDatabaseSchema
cohortTable <- "cohort_characterization"              # this is the name of the output table
# Optional: specify where the temporary files will be created:
options(andromedaTempFolder = file.path(path, "andromedaTemp"))
# Details for connecting to the server:
connectionDetails <- DatabaseConnector::createConnectionDetails(dbms = private.data$dbms,
server = private.data$server,
user = private.data$user,
password = private.data$password,
)
# For Oracle: define a schema that can be used to emulate temp tables:
oracleTempSchema <- NULL
# Start connection
conn <- DatabaseConnector::connect(connectionDetails)
use_python(PYTHON_PATH) # Python interpreter specified in parameters
# https://community.rstudio.com/t/rpytools-error-recurring-with-package-reticulate/66625
# If it does throw the rpytools error, it's just a runtime error that doesn't actually
# Inhibit the scripts.
sys <- import("sys", convert = TRUE) # Fixes run-time warning and error?
py_run_file('inst/py/settings.py')
py_run_file('generating_prevalence_graphs.py')
py_run_file('generating_prevalence_graphs.py')
py_run_file('generating_prevalence_graphs.py')
py_run_file('generating_prevalence_graphs.py')
py_run_file('generating_prevalence_graphs.py')
py_run_file('generating_prevalence_graphs.py')
py_run_file('generating_prevalence_graphs.py')
=======
connectionSpecifications <- cdmSources %>%
dplyr::filter(sequence == 1) %>%
dplyr::filter(database == 'truven_ccae')
dbms <- connectionSpecifications$dbms # example: 'redshift'
port <- connectionSpecifications$port # example: 2234
server <-
connectionSpecifications$server # example: 'fdsfd.yourdatabase.yourserver.com"
library(magrittr)
ROhdsiWebApi::authorizeWebApi("https://epi.jnj.com:8443/WebAPI", "windows") # Windows authentication
cdmSources <- ROhdsiWebApi::getCdmSources(baseUrl = "https://epi.jnj.com:8443/WebAPI") %>%
dplyr::mutate(baseUrl = "https://epi.jnj.com:8443/WebAPI",
dbms = 'redshift',
sourceDialect = 'redshift',
port = 5439,
version = .data$sourceKey %>% substr(., nchar(.) - 3, nchar(.)) %>% as.integer(),
database = .data$sourceKey %>% substr(., 5, nchar(.) - 6)) %>%
dplyr::group_by(.data$database) %>%
dplyr::arrange(dplyr::desc(.data$version)) %>%
dplyr::mutate(sequence = dplyr::row_number()) %>%
dplyr::ungroup() %>%
dplyr::arrange(.data$database, .data$sequence) %>%
dplyr::mutate(server = tolower(paste0(Sys.getenv("serverRoot"),"/", .data$database)))
connectionSpecifications <- cdmSources %>%
dplyr::filter(sequence == 1) %>%
dplyr::filter(database == 'truven_ccae')
dbms <- connectionSpecifications$dbms # example: 'redshift'
port <- connectionSpecifications$port # example: 2234
server <-
connectionSpecifications$server # example: 'fdsfd.yourdatabase.yourserver.com"
cdmDatabaseSchema <-
connectionSpecifications$cdmDatabaseSchema # example: "cdm"
vocabularyDatabaseSchema <-
connectionSpecifications$vocabDatabaseSchema # example: "vocabulary"
databaseId <-
connectionSpecifications$database # example: "truven_ccae"
userNameService = "redShiftUserName" # example: "this is key ring service that securely stores credentials"
passwordService = "redShiftPassword" # example: "this is key ring service that securely stores credentials"
cohortDatabaseSchema = paste0('scratch_', keyring::key_get(service = userNameService))
connectionDetails <- DatabaseConnector::createConnectionDetails(
dbms = dbms,
user = keyring::key_get(service = userNameService),
password = keyring::key_get(service = passwordService),
port = port,
server = server
)
connectionDetails
# Optional: specify where the temporary files will be created:
options(andromedaTempFolder = "D:\\andromedaTemp")
# Start connection
conn <- DatabaseConnector::connect(connectionDetails)
# Instantiate cohorts:
pathToCsv <- system.file("settings", "CohortsToCreateFinal.csv", package = "characterizationPaperPackage")
cohortsToCreate <- readr::read_csv(pathToCsv, col_types = readr::cols())
# Delete table if it already exists, perhaps from a partial execution of the script.
# Commented out, because new users likely won't already have this table.
sql_part1 = "drop table "
sql_part2 = paste(sql_part1, DB, sep='')
sql_part3 = paste(sql_part2, ".results.", sep = '')
sql       = paste(sql_part3, cohortTable, sep = '')
dbms
databaseId
# Delete table if it already exists, perhaps from a partial execution of the script.
# Commented out, because new users likely won't already have this table.
sql = "drop table scratch_jhardi10.testcharacterization;"
sql
cohortDatabaseSchema = paste0('scratch_', keyring::key_get(service = userNameService))
cohortDatabaseSchema
# You do not have to change the below [but you can]
# cdmDatabaseSchema    <- paste(DB, ".dbo", sep='')     # eg: "ohdsi_cumc_2021q1r2.dbo"
# cohortDatabaseSchema <- paste(DB, ".results", sep='') # eg: "ohdsi_cumc_2021q1r2.results"
# vocabularyDatabaseSchema <- cdmDatabaseSchema
cohortTable <- "testcharacterization"              # this is the name of the output table
# Delete table if it already exists, perhaps from a partial execution of the script.
# Commented out, because new users likely won't already have this table.
sql = paste0('drop table ', cohortDatabaseSchema, cohortTable, ';')
sql
# Delete table if it already exists, perhaps from a partial execution of the script.
# Commented out, because new users likely won't already have this table.
sql = paste0('drop table ', cohortDatabaseSchema, '.', cohortTable, ';')
sql
DatabaseConnector::executeSql(
connection = conn,
sql = sql,
profile = FALSE,
progressBar = TRUE,
reportOverallTime = TRUE,
errorReportFile = file.path(getwd(), "errorReportSql.txt"),
runAsBatch = FALSE
)
sql <- paste0('create table ', cohortDatabaseSchema, '.', cohortTable, '(
cohort_definition_id int,
subject_id int,
cohort_start_date date,
cohort_end_date date
);')
sql
cohortsToCreate
cohortsToCreate$name
vocabularyDatabaseSchema
cdmDatabaseSchema
cohortDatabaseSchema
cohortTable
attr(conn, "dbms")
for (i in 1:nrow(cohortsToCreate)) {
# if (cohortsToCreate$name[i] > 2677) {
writeLines(paste("Creating cohort:", cohortsToCreate$name[i]))
sql <- SqlRender::loadRenderTranslateSql(sqlFilename = paste0(cohortsToCreate$name[i], ".sql"),
packageName = "characterizationPaperPackage",
dbms = attr(conn, "dbms"),
oracleTempSchema = oracleTempSchema,
cdm_database_schema = cdmDatabaseSchema,
vocabulary_database_schema = vocabularyDatabaseSchema,
target_database_schema = cohortDatabaseSchema,
target_cohort_table = cohortTable,
target_cohort_id = cohortsToCreate$cohortId[i])
DatabaseConnector::executeSql(conn, sql) #}
}
rlang::last_error()
sql <- paste0('create table ', cohortDatabaseSchema, '.', cohortTable, '(
cohort_definition_id int,
subject_id int,
cohort_start_date date,
cohort_end_date date
);')
DatabaseConnector::executeSql(
connection = conn,
sql = sql,
profile = FALSE,
progressBar = TRUE,
reportOverallTime = TRUE,
errorReportFile = file.path(getwd(), "errorReportSql.txt"),
runAsBatch = FALSE
)
# if (cohortsToCreate$name[i] > 2677) {
i = 1
writeLines(paste("Creating cohort:", cohortsToCreate$name[i]))
sql <- SqlRender::loadRenderTranslateSql(sqlFilename = paste0(cohortsToCreate$name[i], ".sql"),
packageName = "characterizationPaperPackage",
dbms = attr(conn, "dbms"),
oracleTempSchema = oracleTempSchema,
cdm_database_schema = cdmDatabaseSchema,
vocabulary_database_schema = vocabularyDatabaseSchema,
target_database_schema = cohortDatabaseSchema,
target_cohort_table = cohortTable,
target_cohort_id = cohortsToCreate$cohortId[i])
DatabaseConnector::executeSql(conn, sql) #}
rlang::last_error()
sql
View(sql)
>>>>>>> Stashed changes
<<<<<<< HEAD
library(characterizationPaperPackage)
library(magrittr)
ROhdsiWebApi::authorizeWebApi("https://epi.jnj.com:8443/WebAPI", "windows") # Windows authentication
cdmSources <- ROhdsiWebApi::getCdmSources(baseUrl = "https://epi.jnj.com:8443/WebAPI") %>%
dplyr::mutate(baseUrl = "https://epi.jnj.com:8443/WebAPI",
dbms = 'redshift',
sourceDialect = 'redshift',
port = 5439,
version = .data$sourceKey %>% substr(., nchar(.) - 3, nchar(.)) %>% as.integer(),
database = .data$sourceKey %>% substr(., 5, nchar(.) - 6)) %>%
dplyr::group_by(.data$database) %>%
dplyr::arrange(dplyr::desc(.data$version)) %>%
dplyr::mutate(sequence = dplyr::row_number()) %>%
dplyr::ungroup() %>%
dplyr::arrange(.data$database, .data$sequence) %>%
dplyr::mutate(server = tolower(paste0(Sys.getenv("serverRoot"),"/", .data$database)))
# Load the package
library(characterizationPaperPackage)
PYTHON_PATH  <- 'C:\\Users\\admin_jhardi10\\AppData\\Local\\Programs\\Python\\Python39'
=======
# Load the package
library(characterizationPaperPackage)
# Parameters [loaded from credentials.csv, which is not uploaded to Github!]
CREDENTIALS  <- 'C:\\Users\\tonys\\Documents\\Research\\csv\\credentials.csv' # login credentials
PYTHON_PATH  <- 'C:\\Users\\tonys\\AppData\\Local\\Programs\\Python\\Python39'
PACKAGE_PATH <- 'c:/Users/tonys/Research/characterizationPaperPackage/'
DB           <- private.data$db
# You do not have to change the below [but you can]
# cdmDatabaseSchema    <- paste(DB, ".dbo", sep='')     # eg: "ohdsi_cumc_2021q1r2.dbo"
# cohortDatabaseSchema <- paste(DB, ".results", sep='') # eg: "ohdsi_cumc_2021q1r2.results"
# vocabularyDatabaseSchema <- cdmDatabaseSchema
cohortTable <- "testcharacterization"              # this is the name of the output table
# Details for connecting to the server:
connectionDetails <- DatabaseConnector::createConnectionDetails(dbms = private.data$dbms,
server = private.data$server,
user = private.data$user,
password = private.data$password,
)
DB           <- private.data$db
# Parameters [loaded from credentials.csv, which is not uploaded to Github!]
# CREDENTIALS  <- 'C:\\Users\\tonys\\Documents\\Research\\csv\\credentials.csv' # login credentials
private.data = read.csv(CREDENTIALS, fileEncoding = 'UTF-8-BOM')
# Load the package
library(characterizationPaperPackage)
# Parameters [loaded from credentials.csv, which is not uploaded to Github!]
CREDENTIALS  <- 'C:\\Users\\tonys\\Documents\\Research\\csv\\credentials.csv' # login credentials
renv
renv.init()
renv::init()
# Load the package
library(characterizationPaperPackage)
renv::activate()
# Load the package
library(characterizationPaperPackage)
renv::deactivate()
# Load the package
library(characterizationPaperPackage)
# Parameters [loaded from credentials.csv, which is not uploaded to Github!]
# CREDENTIALS  <- 'C:\\Users\\tonys\\Documents\\Research\\csv\\credentials.csv' # login credentials
private.data = read.csv(CREDENTIALS, fileEncoding = 'UTF-8-BOM')
# Parameters [loaded from credentials.csv, which is not uploaded to Github!]
CREDENTIALS  <- 'C:\\Users\\tonys\\Documents\\Research\\csv\\credentials.csv' # login credentials
private.data = read.csv(CREDENTIALS, fileEncoding = 'UTF-8-BOM')
PYTHON_PATH  <- 'C:\\Users\\tonys\\AppData\\Local\\Programs\\Python\\Python39'
PACKAGE_PATH <- 'c:/Users/tonys/Research/characterizationPaperPackage/'
DB           <- private.data$db
>>>>>>> 544e86dbbbf7934179a26cce5a499e12485283e4
# You do not have to change the below [but you can]
# cdmDatabaseSchema    <- paste(DB, ".dbo", sep='')     # eg: "ohdsi_cumc_2021q1r2.dbo"
# cohortDatabaseSchema <- paste(DB, ".results", sep='') # eg: "ohdsi_cumc_2021q1r2.results"
# vocabularyDatabaseSchema <- cdmDatabaseSchema
cohortTable <- "testcharacterization"              # this is the name of the output table
<<<<<<< HEAD
connectionSpecifications <- cdmSources %>%
dplyr::filter(sequence == 1) %>%
dplyr::filter(database == 'truven_ccae')
dbms <- connectionSpecifications$dbms # example: 'redshift'
port <- connectionSpecifications$port # example: 2234
server <-
connectionSpecifications$server # example: 'fdsfd.yourdatabase.yourserver.com"
cdmDatabaseSchema <-
connectionSpecifications$cdmDatabaseSchema # example: "cdm"
vocabularyDatabaseSchema <-
connectionSpecifications$vocabDatabaseSchema # example: "vocabulary"
databaseId <-
connectionSpecifications$database # example: "truven_ccae"
userNameService = "redShiftUserName" # example: "this is key ring service that securely stores credentials"
passwordService = "redShiftPassword" # example: "this is key ring service that securely stores credentials"
cohortDatabaseSchema = paste0('scratch_', keyring::key_get(service = userNameService))
connectionDetails <- DatabaseConnector::createConnectionDetails(
dbms = dbms,
user = keyring::key_get(service = userNameService),
password = keyring::key_get(service = passwordService),
port = port,
server = server
)
# Optional: specify where the temporary files will be created:
options(andromedaTempFolder = "D:\\andromedaTemp")
=======
# Details for connecting to the server:
connectionDetails <- DatabaseConnector::createConnectionDetails(dbms = private.data$dbms,
server = private.data$server,
user = private.data$user,
password = private.data$password,
)
# Start connection
conn <- DatabaseConnector::connect(connectionDetails)
# Instantiate cohorts:
pathToCsv <- system.file("settings", "CohortsToCreateFinal.csv", package = "characterizationPaperPackage")
cohortsToCreate <- readr::read_csv(pathToCsv, col_types = readr::cols())
# Run processing for all_condition_occurrence_summary.sql script
sql <- SqlRender::loadRenderTranslateSql(sqlFilename = "all_condition_occurrence_summary.sql",
packageName = "characterizationPaperPackage",
dbms = attr(conn, "dbms"),
cdm_database_schema = cdmDatabaseSchema,
source_name = "ohdsi_cumc_2021q1r2")
# Load the package
library(characterizationPaperPackage)
detach("package:characterizationPaperPackage", unload = TRUE)
library(characterizationPaperPackage)
# Load the package
library(characterizationPaperPackage)
# Run processing for all_condition_occurrence_summary.sql script
sql <- SqlRender::loadRenderTranslateSql(sqlFilename = "all_condition_occurrence_summary.sql",
packageName = "characterizationPaperPackage",
dbms = attr(conn, "dbms"),
cdm_database_schema = cdmDatabaseSchema,
source_name = "ohdsi_cumc_2021q1r2")
sql
library(ROhdsiWebApi)
detach("package:reticulate", unload = TRUE)
detach("package:ROhdsiWebApi", unload = TRUE)
library(characterizationPaperPackage)
# Load the package
library(characterizationPaperPackage)
# Parameters [loaded from credentials.csv, which is not uploaded to Github!]
# CREDENTIALS  <- 'C:\\Users\\tonys\\Documents\\Research\\csv\\credentials.csv' # login credentials
private.data = read.csv(CREDENTIALS, fileEncoding = 'UTF-8-BOM')
# Load the package
library(characterizationPaperPackage)
# Parameters [loaded from credentials.csv, which is not uploaded to Github!]
CREDENTIALS  <- 'C:\\Users\\tonys\\Documents\\Research\\csv\\credentials.csv' # login credentials
private.data = read.csv(CREDENTIALS, fileEncoding = 'UTF-8-BOM')
PYTHON_PATH  <- 'C:\\Users\\tonys\\AppData\\Local\\Programs\\Python\\Python39'
# PYTHON_PATH  <- 'C:\\Users\\admin_jhardi10\\AppData\\Local\\Programs\\Python\\Python39'
PACKAGE_PATH <- 'c:/Users/tonys/Research/characterizationPaperPackage/'
DB           <- private.data$db
# You do not have to change the below [but you can]
cdmDatabaseSchema    <- paste(DB, ".dbo", sep='')     # eg: "ohdsi_cumc_2021q1r2.dbo"
cohortDatabaseSchema <- paste(DB, ".results", sep='') # eg: "ohdsi_cumc_2021q1r2.results"
vocabularyDatabaseSchema <- cdmDatabaseSchema
cohortTable <- "testcharacterization"              # this is the name of the output table
# Optional: specify where the temporary files will be created:
options(andromedaTempFolder = "D:\\andromedaTemp")
connectionDetails <- DatabaseConnector::createConnectionDetails(dbms = private.data$dbms,
server = private.data$server,
user = private.data$user,
password = private.data$password,
)
# For Oracle: define a schema that can be used to emulate temp tables:
oracleTempSchema <- NULL
# Start connection
conn <- DatabaseConnector::connect(connectionDetails)
# Instantiate cohorts:
pathToCsv <- system.file("settings", "CohortsToCreateFinal.csv", package = "characterizationPaperPackage")
cohortsToCreate <- readr::read_csv(pathToCsv, col_types = readr::cols())
# Run processing for all_condition_occurrence_summary.sql script
sql <- SqlRender::loadRenderTranslateSql(sqlFilename = "all_condition_occurrence_summary.sql",
packageName = "characterizationPaperPackage",
dbms = attr(conn, "dbms"),
cdm_database_schema = cdmDatabaseSchema,
source_name = "ohdsi_cumc_2021q1r2")
sql
# Run processing for all_condition_occurrence_summary.sql script
sql <- SqlRender::loadRenderTranslateSql(sqlFilename = "all_condition_occurrence_summary.sql",
packageName = "characterizationPaperPackage",
dbms = attr(conn, "dbms"),
cdm_database_schema = cdmDatabaseSchema,
source_name = "ohdsi_cumc_2021q1r2")
disconnect(conn)
# Load the package
library(characterizationPaperPackage)
# Parameters [loaded from credentials.csv, which is not uploaded to Github!]
CREDENTIALS  <- 'C:\\Users\\tonys\\Documents\\Research\\csv\\credentials.csv' # login credentials
private.data = read.csv(CREDENTIALS, fileEncoding = 'UTF-8-BOM')
PYTHON_PATH  <- 'C:\\Users\\tonys\\AppData\\Local\\Programs\\Python\\Python39'
# PYTHON_PATH  <- 'C:\\Users\\admin_jhardi10\\AppData\\Local\\Programs\\Python\\Python39'
PACKAGE_PATH <- 'c:/Users/tonys/Research/characterizationPaperPackage/'
DB           <- private.data$db
# You do not have to change the below [but you can]
cdmDatabaseSchema    <- paste(DB, ".dbo", sep='')     # eg: "ohdsi_cumc_2021q1r2.dbo"
cohortDatabaseSchema <- paste(DB, ".results", sep='') # eg: "ohdsi_cumc_2021q1r2.results"
vocabularyDatabaseSchema <- cdmDatabaseSchema
cohortTable <- "testcharacterization"              # this is the name of the output table
# Optional: specify where the temporary files will be created:
options(andromedaTempFolder = "D:\\andromedaTemp")
connectionDetails <- DatabaseConnector::createConnectionDetails(dbms = private.data$dbms,
server = private.data$server,
user = private.data$user,
password = private.data$password,
)
>>>>>>> 544e86dbbbf7934179a26cce5a499e12485283e4
# For Oracle: define a schema that can be used to emulate temp tables:
oracleTempSchema <- NULL
# Start connection
conn <- DatabaseConnector::connect(connectionDetails)
# Instantiate cohorts:
pathToCsv <- system.file("settings", "CohortsToCreateFinal.csv", package = "characterizationPaperPackage")
cohortsToCreate <- readr::read_csv(pathToCsv, col_types = readr::cols())
# Delete table if it already exists, perhaps from a partial execution of the script.
# Commented out, because new users likely won't already have this table.
sql = paste0('drop table ', cohortDatabaseSchema, '.', cohortTable, ';')
<<<<<<< HEAD
DatabaseConnector::executeSql(
connection = conn,
sql = sql,
profile = FALSE,
progressBar = TRUE,
reportOverallTime = TRUE,
errorReportFile = file.path(getwd(), "errorReportSql.txt"),
runAsBatch = FALSE
)
sql <- paste0('create table ', cohortDatabaseSchema, '.', cohortTable, '(
cohort_definition_id bigint,
subject_id bigint,
cohort_start_date date,
cohort_end_date date
);')
DatabaseConnector::executeSql(
connection = conn,
sql = sql,
profile = FALSE,
progressBar = TRUE,
reportOverallTime = TRUE,
errorReportFile = file.path(getwd(), "errorReportSql.txt"),
runAsBatch = FALSE
)
# if (cohortsToCreate$name[i] > 2677) {
i = 1
writeLines(paste("Creating cohort:", cohortsToCreate$name[i]))
sql <- SqlRender::loadRenderTranslateSql(sqlFilename = paste0(cohortsToCreate$name[i], ".sql"),
packageName = "characterizationPaperPackage",
dbms = attr(conn, "dbms"),
oracleTempSchema = oracleTempSchema,
cdm_database_schema = cdmDatabaseSchema,
vocabulary_database_schema = vocabularyDatabaseSchema,
target_database_schema = cohortDatabaseSchema,
target_cohort_table = cohortTable,
target_cohort_id = cohortsToCreate$cohortId[i])
DatabaseConnector::executeSql(conn, sql) #}
# Run processing for all_condition_occurrence_summary.sql script
sql <- SqlRender::loadRenderTranslateSql(sqlFilename = "all_condition_occurrence_summary.sql",
packageName = "characterizationPaperPackage",
dbms = attr(conn, "dbms"))
DatabaseConnector::executeSql(conn, sql)
cohortsToCreate
cohortsToCreate$name[i]
=======
# Run processing for all_condition_occurrence_summary.sql script
sql <- SqlRender::loadRenderTranslateSql(sqlFilename = "all_condition_occurrence_summary.sql",
packageName = "characterizationPaperPackage",
dbms = attr(conn, "dbms"),
cdm_database_schema = cdmDatabaseSchema,
source_name = "ohdsi_cumc_2021q1r2")
sql
>>>>>>> 544e86dbbbf7934179a26cce5a499e12485283e4
