=======
# Details for connecting to the server:
connectionDetails <- DatabaseConnector::createConnectionDetails(dbms = private.data$dbms,
server = private.data$server,
user = private.data$user,
password = private.data$password,
)
# Start connection
conn <- DatabaseConnector::connect(connectionDetails)
# Instantiate cohorts:
pathToCsv <- system.file("settings", "CohortsToCreateFinal.csv", package = "characterizationPaperPackage")
cohortsToCreate <- readr::read_csv(pathToCsv, col_types = readr::cols())
# Run processing for all_condition_occurrence_summary.sql script
sql <- SqlRender::loadRenderTranslateSql(sqlFilename = "all_condition_occurrence_summary.sql",
packageName = "characterizationPaperPackage",
dbms = attr(conn, "dbms"),
cdm_database_schema = cdmDatabaseSchema,
source_name = "ohdsi_cumc_2021q1r2")
# Load the package
library(characterizationPaperPackage)
detach("package:characterizationPaperPackage", unload = TRUE)
library(characterizationPaperPackage)
# Load the package
library(characterizationPaperPackage)
# Run processing for all_condition_occurrence_summary.sql script
sql <- SqlRender::loadRenderTranslateSql(sqlFilename = "all_condition_occurrence_summary.sql",
packageName = "characterizationPaperPackage",
dbms = attr(conn, "dbms"),
cdm_database_schema = cdmDatabaseSchema,
source_name = "ohdsi_cumc_2021q1r2")
sql
library(ROhdsiWebApi)
detach("package:reticulate", unload = TRUE)
detach("package:ROhdsiWebApi", unload = TRUE)
library(characterizationPaperPackage)
# Load the package
library(characterizationPaperPackage)
# Parameters [loaded from credentials.csv, which is not uploaded to Github!]
# CREDENTIALS  <- 'C:\\Users\\tonys\\Documents\\Research\\csv\\credentials.csv' # login credentials
private.data = read.csv(CREDENTIALS, fileEncoding = 'UTF-8-BOM')
# Load the package
library(characterizationPaperPackage)
# Parameters [loaded from credentials.csv, which is not uploaded to Github!]
CREDENTIALS  <- 'C:\\Users\\tonys\\Documents\\Research\\csv\\credentials.csv' # login credentials
private.data = read.csv(CREDENTIALS, fileEncoding = 'UTF-8-BOM')
PYTHON_PATH  <- 'C:\\Users\\tonys\\AppData\\Local\\Programs\\Python\\Python39'
# PYTHON_PATH  <- 'C:\\Users\\admin_jhardi10\\AppData\\Local\\Programs\\Python\\Python39'
PACKAGE_PATH <- 'c:/Users/tonys/Research/characterizationPaperPackage/'
DB           <- private.data$db
# You do not have to change the below [but you can]
cdmDatabaseSchema    <- paste(DB, ".dbo", sep='')     # eg: "ohdsi_cumc_2021q1r2.dbo"
cohortDatabaseSchema <- paste(DB, ".results", sep='') # eg: "ohdsi_cumc_2021q1r2.results"
vocabularyDatabaseSchema <- cdmDatabaseSchema
cohortTable <- "testcharacterization"              # this is the name of the output table
# Optional: specify where the temporary files will be created:
options(andromedaTempFolder = "D:\\andromedaTemp")
connectionDetails <- DatabaseConnector::createConnectionDetails(dbms = private.data$dbms,
server = private.data$server,
user = private.data$user,
password = private.data$password,
)
# For Oracle: define a schema that can be used to emulate temp tables:
oracleTempSchema <- NULL
# Start connection
conn <- DatabaseConnector::connect(connectionDetails)
# Instantiate cohorts:
pathToCsv <- system.file("settings", "CohortsToCreateFinal.csv", package = "characterizationPaperPackage")
cohortsToCreate <- readr::read_csv(pathToCsv, col_types = readr::cols())
# Run processing for all_condition_occurrence_summary.sql script
sql <- SqlRender::loadRenderTranslateSql(sqlFilename = "all_condition_occurrence_summary.sql",
packageName = "characterizationPaperPackage",
dbms = attr(conn, "dbms"),
cdm_database_schema = cdmDatabaseSchema,
source_name = "ohdsi_cumc_2021q1r2")
sql
# Run processing for all_condition_occurrence_summary.sql script
sql <- SqlRender::loadRenderTranslateSql(sqlFilename = "all_condition_occurrence_summary.sql",
packageName = "characterizationPaperPackage",
dbms = attr(conn, "dbms"),
cdm_database_schema = cdmDatabaseSchema,
source_name = "ohdsi_cumc_2021q1r2")
disconnect(conn)
# Load the package
library(characterizationPaperPackage)
# Parameters [loaded from credentials.csv, which is not uploaded to Github!]
CREDENTIALS  <- 'C:\\Users\\tonys\\Documents\\Research\\csv\\credentials.csv' # login credentials
private.data = read.csv(CREDENTIALS, fileEncoding = 'UTF-8-BOM')
PYTHON_PATH  <- 'C:\\Users\\tonys\\AppData\\Local\\Programs\\Python\\Python39'
# PYTHON_PATH  <- 'C:\\Users\\admin_jhardi10\\AppData\\Local\\Programs\\Python\\Python39'
PACKAGE_PATH <- 'c:/Users/tonys/Research/characterizationPaperPackage/'
DB           <- private.data$db
# You do not have to change the below [but you can]
cdmDatabaseSchema    <- paste(DB, ".dbo", sep='')     # eg: "ohdsi_cumc_2021q1r2.dbo"
cohortDatabaseSchema <- paste(DB, ".results", sep='') # eg: "ohdsi_cumc_2021q1r2.results"
vocabularyDatabaseSchema <- cdmDatabaseSchema
cohortTable <- "testcharacterization"              # this is the name of the output table
# Optional: specify where the temporary files will be created:
options(andromedaTempFolder = "D:\\andromedaTemp")
connectionDetails <- DatabaseConnector::createConnectionDetails(dbms = private.data$dbms,
server = private.data$server,
user = private.data$user,
password = private.data$password,
)
>>>>>>> 544e86dbbbf7934179a26cce5a499e12485283e4
# For Oracle: define a schema that can be used to emulate temp tables:
oracleTempSchema <- NULL
# Start connection
conn <- DatabaseConnector::connect(connectionDetails)
# Instantiate cohorts:
pathToCsv <- system.file("settings", "CohortsToCreateFinal.csv", package = "characterizationPaperPackage")
cohortsToCreate <- readr::read_csv(pathToCsv, col_types = readr::cols())
# Delete table if it already exists, perhaps from a partial execution of the script.
# Commented out, because new users likely won't already have this table.
sql = paste0('drop table ', cohortDatabaseSchema, '.', cohortTable, ';')
<<<<<<< HEAD
DatabaseConnector::executeSql(
connection = conn,
sql = sql,
profile = FALSE,
progressBar = TRUE,
reportOverallTime = TRUE,
errorReportFile = file.path(getwd(), "errorReportSql.txt"),
runAsBatch = FALSE
)
sql <- paste0('create table ', cohortDatabaseSchema, '.', cohortTable, '(
cohort_definition_id bigint,
subject_id bigint,
cohort_start_date date,
cohort_end_date date
);')
DatabaseConnector::executeSql(
connection = conn,
sql = sql,
profile = FALSE,
progressBar = TRUE,
reportOverallTime = TRUE,
errorReportFile = file.path(getwd(), "errorReportSql.txt"),
runAsBatch = FALSE
)
# if (cohortsToCreate$name[i] > 2677) {
i = 1
writeLines(paste("Creating cohort:", cohortsToCreate$name[i]))
sql <- SqlRender::loadRenderTranslateSql(sqlFilename = paste0(cohortsToCreate$name[i], ".sql"),
packageName = "characterizationPaperPackage",
dbms = attr(conn, "dbms"),
oracleTempSchema = oracleTempSchema,
cdm_database_schema = cdmDatabaseSchema,
vocabulary_database_schema = vocabularyDatabaseSchema,
target_database_schema = cohortDatabaseSchema,
target_cohort_table = cohortTable,
target_cohort_id = cohortsToCreate$cohortId[i])
DatabaseConnector::executeSql(conn, sql) #}
# Run processing for all_condition_occurrence_summary.sql script
sql <- SqlRender::loadRenderTranslateSql(sqlFilename = "all_condition_occurrence_summary.sql",
packageName = "characterizationPaperPackage",
dbms = attr(conn, "dbms"))
DatabaseConnector::executeSql(conn, sql)
cohortsToCreate
cohortsToCreate$name[i]
=======
# Run processing for all_condition_occurrence_summary.sql script
sql <- SqlRender::loadRenderTranslateSql(sqlFilename = "all_condition_occurrence_summary.sql",
packageName = "characterizationPaperPackage",
dbms = attr(conn, "dbms"),
cdm_database_schema = cdmDatabaseSchema,
source_name = "ohdsi_cumc_2021q1r2")
sql
>>>>>>> 544e86dbbbf7934179a26cce5a499e12485283e4
library(characterizationPaperPackage)
library(characterizationPaperPackage)
keyring::key_get(service = asdf)
keyring::manual()
help?
a
?keyring
server
py_run_file('inst/py/settings_sqlserver.py')
# Load the package
library(characterizationPaperPackage)
py_run_file('inst/py/settings_sqlserver.py')
py_run_file('inst/py/settings_sqlserver.py')
library(characterizationPaperPackage)
# Load the package
library(characterizationPaperPackage)
# Parameters [loaded from credentials.csv, which is not uploaded to Github!]
CREDENTIALS  <- 'C:\\Users\\tonys\\Documents\\Research\\csv\\credentials.csv' # login credentials
private.data = read.csv(CREDENTIALS, fileEncoding = 'UTF-8-BOM')
PYTHON_PATH  <- 'C:\\Users\\tonys\\AppData\\Local\\Programs\\Python\\Python39'
# PYTHON_PATH  <- 'C:\\Users\\admin_jhardi10\\AppData\\Local\\Programs\\Python\\Python39'
PACKAGE_PATH <- 'c:/Users/tonys/Research/characterizationPaperPackage/'
DB           <- private.data$db
# You do not have to change the below [but you can]
cdmDatabaseSchema    <- paste(DB, ".dbo", sep='')     # eg: "ohdsi_cumc_2021q1r2.dbo"
cohortDatabaseSchema <- paste(DB, ".results", sep='') # eg: "ohdsi_cumc_2021q1r2.results"
vocabularyDatabaseSchema <- cdmDatabaseSchema
cohortTable <- "cohort_characterization"              # this is the name of the output table
connectionDetails <- DatabaseConnector::createConnectionDetails(dbms = private.data$dbms,
server = private.data$server,
user = private.data$user,
password = private.data$password,
)
# Start connection
conn <- DatabaseConnector::connect(connectionDetails)
# Run processing for all_condition_occurrence_summary.sql script
sql <- SqlRender::loadRenderTranslateSql(sqlFilename = "all_condition_occurrence_summary.sql",
packageName = "characterizationPaperPackage",
dbms = attr(conn, "dbms"),
cdm_database = "ohdsi_cumc_2021q1r2",  # This will need to change to your DB name
source_name = "'ohdsi_cumc_2021q1r2'", # Note the additional ''s.
results_database_schema = "results",   # e.g. for me, I save to results; e.g. scratch_jhard10
results_sex_diff_summary = "results_sex_diff_summary")
library(characterizationPaperPackage)
# Load the package
library(characterizationPaperPackage)
# Parameters [loaded from credentials.csv, which is not uploaded to Github!]
CREDENTIALS  <- 'C:\\Users\\tonys\\Documents\\Research\\csv\\credentials.csv' # login credentials
private.data = read.csv(CREDENTIALS, fileEncoding = 'UTF-8-BOM')
PYTHON_PATH  <- 'C:\\Users\\tonys\\AppData\\Local\\Programs\\Python\\Python39'
# PYTHON_PATH  <- 'C:\\Users\\admin_jhardi10\\AppData\\Local\\Programs\\Python\\Python39'
PACKAGE_PATH <- 'c:/Users/tonys/Research/characterizationPaperPackage/'
DB           <- private.data$db
# You do not have to change the below [but you can]
cdmDatabaseSchema    <- paste(DB, ".dbo", sep='')     # eg: "ohdsi_cumc_2021q1r2.dbo"
cohortDatabaseSchema <- paste(DB, ".results", sep='') # eg: "ohdsi_cumc_2021q1r2.results"
vocabularyDatabaseSchema <- cdmDatabaseSchema
cohortTable <- "cohort_characterization"              # this is the name of the output table for the cohorts
# Optional: specify where the temporary files will be created:
options(andromedaTempFolder = "D:\\andromedaTemp")
connectionDetails <- DatabaseConnector::createConnectionDetails(dbms = private.data$dbms,
server = private.data$server,
user = private.data$user,
password = private.data$password,
)
# For Oracle: define a schema that can be used to emulate temp tables:
oracleTempSchema <- NULL
# Start connection
conn <- DatabaseConnector::connect(connectionDetails)
# Run processing for all_condition_occurrence_summary.sql script
sql <- SqlRender::loadRenderTranslateSql(sqlFilename = "all_condition_occurrence_summary.sql",
packageName = "characterizationPaperPackage",
dbms = attr(conn, "dbms"),
cdm_database = "ohdsi_cumc_2021q1r2",  # This will need to change to your DB name
source_name = "'ohdsi_cumc_2021q1r2'", # Note the additional ''s.
results_database_schema = "results",   # e.g. for me, I save to results; e.g. scratch_jhard10
results_sex_diff_summary = "results_sex_diff_summary")
# Run processing for all_condition_occurrence_summary.sql script
sql <- SqlRender::loadRenderTranslateSql(sqlFilename = "all_condition_occurrence_summary.sql",
packageName = "characterizationPaperPackage",
dbms = attr(conn, "dbms"),
cdm_database = "ohdsi_cumc_2021q1r2",  # This will need to change to your DB name
source_name = "'ohdsi_cumc_2021q1r2'", # Note the additional ''s.
results_database_schema = "results",   # e.g. for me, I save to results
results_sex_diff_summary = "results_sex_diff_summary")
DatabaseConnector::executeSql(conn, sql)
library(characterizationPaperPackage)
# Load the package
library(characterizationPaperPackage)
# Parameters [loaded from credentials.csv, which is not uploaded to Github!]
CREDENTIALS  <- 'C:\\Users\\tonys\\Documents\\Research\\csv\\credentials.csv' # login credentials
private.data = read.csv(CREDENTIALS, fileEncoding = 'UTF-8-BOM')
PYTHON_PATH  <- 'C:\\Users\\tonys\\AppData\\Local\\Programs\\Python\\Python39'
# PYTHON_PATH  <- 'C:\\Users\\admin_jhardi10\\AppData\\Local\\Programs\\Python\\Python39'
PACKAGE_PATH <- 'c:/Users/tonys/Research/characterizationPaperPackage/'
DB           <- private.data$db
# You do not have to change the below [but you can]
cdmDatabaseSchema    <- paste(DB, ".dbo", sep='')     # eg: "ohdsi_cumc_2021q1r2.dbo"
cohortDatabaseSchema <- paste(DB, ".results", sep='') # eg: "ohdsi_cumc_2021q1r2.results"
vocabularyDatabaseSchema <- cdmDatabaseSchema
cohortTable <- "cohort_characterization"              # this is the name of the output table for the cohorts
# Optional: specify where the temporary files will be created:
options(andromedaTempFolder = "D:\\andromedaTemp")
connectionDetails <- DatabaseConnector::createConnectionDetails(dbms = private.data$dbms,
server = private.data$server,
user = private.data$user,
password = private.data$password,
)
# For Oracle: define a schema that can be used to emulate temp tables:
oracleTempSchema <- NULL
# Start connection
conn <- DatabaseConnector::connect(connectionDetails)
# Run processing sexdiff_cohort_reference_ver5.sql script
sql <- SqlRender::loadRenderTranslateSql(sqlFilename = "sexdiff_cohort_reference_ver5.sql",
packageName = "characterizationPaperPackage",
dbms = attr(conn, "dbms"),
cdm_database = "ohdsi_cumc_2021q1r2",
source_name = "'ohdsi_cumc_2021q1r2'",
results_database_schema = "results",
target_cohort_table = cohortTable,
sexdiff_cohort_covarate_summary_v5 = "sexdiff_cohort_covarate_summary_v5",
sexdiff_cohort_ttonset_v5 = "sexdiff_cohort_ttonset_v5",
sexdiff_cohort_ttonset_summary_v5 = "sexdiff_cohort_ttonset_summary_v5")
library(characterizationPaperPackage)
# Parameters [loaded from credentials.csv, which is not uploaded to Github!]
CREDENTIALS  <- 'C:\\Users\\tonys\\Documents\\Research\\csv\\credentials.csv' # login credentials
private.data = read.csv(CREDENTIALS, fileEncoding = 'UTF-8-BOM')
PYTHON_PATH  <- 'C:\\Users\\tonys\\AppData\\Local\\Programs\\Python\\Python39'
# PYTHON_PATH  <- 'C:\\Users\\admin_jhardi10\\AppData\\Local\\Programs\\Python\\Python39'
PACKAGE_PATH <- 'c:/Users/tonys/Research/characterizationPaperPackage/'
DB           <- private.data$db
# You do not have to change the below [but you can]
cdmDatabaseSchema    <- paste(DB, ".dbo", sep='')     # eg: "ohdsi_cumc_2021q1r2.dbo"
cohortDatabaseSchema <- paste(DB, ".results", sep='') # eg: "ohdsi_cumc_2021q1r2.results"
vocabularyDatabaseSchema <- cdmDatabaseSchema
cohortTable <- "cohort_characterization"              # this is the name of the output table for the cohorts
# Optional: specify where the temporary files will be created:
options(andromedaTempFolder = "D:\\andromedaTemp")
connectionDetails <- DatabaseConnector::createConnectionDetails(dbms = private.data$dbms,
server = private.data$server,
user = private.data$user,
password = private.data$password,
)
# For Oracle: define a schema that can be used to emulate temp tables:
oracleTempSchema <- NULL
# Start connection
conn <- DatabaseConnector::connect(connectionDetails)
# Run processing sexdiff_cohort_reference_ver5.sql script
sql <- SqlRender::loadRenderTranslateSql(sqlFilename = "sexdiff_cohort_reference_ver5.sql",
packageName = "characterizationPaperPackage",
dbms = attr(conn, "dbms"),
cdm_database = "ohdsi_cumc_2021q1r2",
source_name = "'ohdsi_cumc_2021q1r2'",
results_database_schema = "results",
target_cohort_table = cohortTable,
sexdiff_cohort_covarate_summary_v5 = "sexdiff_cohort_covarate_summary_v5",
sexdiff_cohort_ttonset_v5 = "sexdiff_cohort_ttonset_v5",
sexdiff_cohort_ttonset_summary_v5 = "sexdiff_cohort_ttonset_summary_v5")
DatabaseConnector::executeSql(conn, sql)
results_database_schema = "results"
# Run processing for all_condition_occurrence_summary.sql script
sql <- SqlRender::loadRenderTranslateSql(sqlFilename = "all_condition_occurrence_summary.sql",
packageName = "characterizationPaperPackage",
dbms = attr(conn, "dbms"),
cdm_database = "ohdsi_cumc_2021q1r2",  # This will need to change to your DB name
source_name = "'ohdsi_cumc_2021q1r2'", # Note the additional ''s.
results_database_schema = results_database_schema,   # e.g. for me, I save to results
results_sex_diff_summary = "sex_diff_summary")
DatabaseConnector::executeSql(conn, sql)
tablepaths <- c(results_database_schema, cohortTable)
tablepaths
tablepaths <- c(results_database_schema, cohortTable)
write.table(tablepaths, 'tablepaths.txt', sep = ",", row.names=FALSE, col.names=FALSE)
tablepaths <- (results_database_schema, cohortTable)
use_python(PYTHON_PATH) # Python interpreter specified in parameters
# https://community.rstudio.com/t/rpytools-error-recurring-with-package-reticulate/66625
# If it does throw the rpytools error, it's just a runtime error that doesn't actually
# Inhibit the scripts.
sys <- import("sys", convert = TRUE) # Fixes run-time warning and error?
use_python(PYTHON_PATH) # Python interpreter specified in parameters
# https://community.rstudio.com/t/rpytools-error-recurring-with-package-reticulate/66625
# If it does throw the rpytools error, it's just a runtime error that doesn't actually
# Inhibit the scripts.
sys <- import("sys", convert = TRUE) # Fixes run-time warning and error?
use_python(PYTHON_PATH) # Python interpreter specified in parameters
# https://community.rstudio.com/t/rpytools-error-recurring-with-package-reticulate/66625
# If it does throw the rpytools error, it's just a runtime error that doesn't actually
# Inhibit the scripts.
sys <- import("sys", convert = TRUE) # Fixes run-time warning and error?
sys <- import("sys", convert = TRUE) # Fixes run-time warning and error?
py_run_file('inst/py/testing_imports.py')
library(characterizationPaperPackage)
DatabaseConnector::executeSql(conn, sql)
# Save table FP to file, so it can be parsed in Python.
tablepaths <- c(results_database_schema, cohortTable)
write.table(tablepaths, 'tablepaths.txt', sep = ",", row.names=FALSE, col.names=FALSE)
# Parameters [loaded from credentials.csv, which is not uploaded to Github!]
CREDENTIALS  <- 'C:\\Users\\tonys\\Documents\\Research\\csv\\credentials.csv' # login credentials
private.data = read.csv(CREDENTIALS, fileEncoding = 'UTF-8-BOM')
PYTHON_PATH  <- 'C:\\Users\\tonys\\AppData\\Local\\Programs\\Python\\Python39'
# PYTHON_PATH  <- 'C:\\Users\\admin_jhardi10\\AppData\\Local\\Programs\\Python\\Python39'
PACKAGE_PATH <- 'c:/Users/tonys/Research/characterizationPaperPackage/'
DB           <- private.data$db
# You do not have to change the below [but you can]
cdmDatabaseSchema    <- paste(DB, ".dbo", sep='')     # eg: "ohdsi_cumc_2021q1r2.dbo"
cohortDatabaseSchema <- paste(DB, ".results", sep='') # eg: "ohdsi_cumc_2021q1r2.results"
vocabularyDatabaseSchema <- cdmDatabaseSchema
cohortTable <- "cohort_characterization"              # this is the name of the output table for the cohorts
# Optional: specify where the temporary files will be created:
options(andromedaTempFolder = "D:\\andromedaTemp")
connectionDetails <- DatabaseConnector::createConnectionDetails(dbms = private.data$dbms,
server = private.data$server,
user = private.data$user,
password = private.data$password,
)
# For Oracle: define a schema that can be used to emulate temp tables:
oracleTempSchema <- NULL
# Start connection
conn <- DatabaseConnector::connect(connectionDetails)
# Save table FP to file, so it can be parsed in Python.
tablepaths <- c(results_database_schema, cohortTable)
write.table(tablepaths, 'tablepaths.txt', sep = ",", row.names=FALSE, col.names=FALSE)
use_python(PYTHON_PATH) # Python interpreter specified in parameters
# https://community.rstudio.com/t/rpytools-error-recurring-with-package-reticulate/66625
# If it does throw the rpytools error, it's just a runtime error that doesn't actually
# Inhibit the scripts. Just run the same lines twice and it fixes it...
sys <- import("sys", convert = TRUE) # Fixes run-time warning and error?
sys <- import("sys", convert = TRUE) # Fixes run-time warning and error?
py_run_file('inst/py/testing_imports.py')
py_run_file('testing_imports.py')
library(characterizationPaperPackage)
# Load the package
library(characterizationPaperPackage)
# Parameters [loaded from credentials.csv, which is not uploaded to Github!]
CREDENTIALS  <- 'C:\\Users\\tonys\\Documents\\Research\\csv\\credentials.csv' # login credentials
private.data = read.csv(CREDENTIALS, fileEncoding = 'UTF-8-BOM')
PYTHON_PATH  <- 'C:\\Users\\tonys\\AppData\\Local\\Programs\\Python\\Python39'
# PYTHON_PATH  <- 'C:\\Users\\admin_jhardi10\\AppData\\Local\\Programs\\Python\\Python39'
PACKAGE_PATH <- 'c:/Users/tonys/Research/characterizationPaperPackage/'
DB           <- private.data$db
# You do not have to change the below [but you can]
cdmDatabaseSchema    <- paste(DB, ".dbo", sep='')     # eg: "ohdsi_cumc_2021q1r2.dbo"
cohortDatabaseSchema <- paste(DB, ".results", sep='') # eg: "ohdsi_cumc_2021q1r2.results"
vocabularyDatabaseSchema <- cdmDatabaseSchema
cohortTable <- "cohort_characterization"              # this is the name of the output table for the cohorts
# Optional: specify where the temporary files will be created:
options(andromedaTempFolder = "D:\\andromedaTemp")
connectionDetails <- DatabaseConnector::createConnectionDetails(dbms = private.data$dbms,
server = private.data$server,
user = private.data$user,
password = private.data$password,
)
# For Oracle: define a schema that can be used to emulate temp tables:
oracleTempSchema <- NULL
# Start connection
conn <- DatabaseConnector::connect(connectionDetails)
results_database_schema = "results"
# Save table FP to file, so it can be parsed in Python.
tablepaths <- c(results_database_schema, cohortTable)
write.table(tablepaths, 'tablepaths.txt', sep = ",", row.names=FALSE, col.names=FALSE)
use_python(PYTHON_PATH) # Python interpreter specified in parameters
# https://community.rstudio.com/t/rpytools-error-recurring-with-package-reticulate/66625
# If it does throw the rpytools error, it's just a runtime error that doesn't actually
# Inhibit the scripts. Just run the same lines twice and it fixes it...
sys <- import("sys", convert = TRUE) # Fixes run-time warning and error?
sys <- import("sys", convert = TRUE) # Fixes run-time warning and error?
py_run_file('inst/py/testing_imports.py')
py_run_file('testing_imports.py')
library(characterizationPaperPackage)
# Load the package
library(characterizationPaperPackage)
# Parameters [loaded from credentials.csv, which is not uploaded to Github!]
CREDENTIALS  <- 'C:\\Users\\tonys\\Documents\\Research\\csv\\credentials.csv' # login credentials
private.data = read.csv(CREDENTIALS, fileEncoding = 'UTF-8-BOM')
PYTHON_PATH  <- 'C:\\Users\\tonys\\AppData\\Local\\Programs\\Python\\Python39'
# PYTHON_PATH  <- 'C:\\Users\\admin_jhardi10\\AppData\\Local\\Programs\\Python\\Python39'
PACKAGE_PATH <- 'c:/Users/tonys/Research/characterizationPaperPackage/'
DB           <- private.data$db
# You do not have to change the below [but you can]
cdmDatabaseSchema    <- paste(DB, ".dbo", sep='')     # eg: "ohdsi_cumc_2021q1r2.dbo"
cohortDatabaseSchema <- paste(DB, ".results", sep='') # eg: "ohdsi_cumc_2021q1r2.results"
vocabularyDatabaseSchema <- cdmDatabaseSchema
cohortTable <- "cohort_characterization"              # this is the name of the output table for the cohorts
# Optional: specify where the temporary files will be created:
options(andromedaTempFolder = "D:\\andromedaTemp")
connectionDetails <- DatabaseConnector::createConnectionDetails(dbms = private.data$dbms,
server = private.data$server,
user = private.data$user,
password = private.data$password,
)
# For Oracle: define a schema that can be used to emulate temp tables:
oracleTempSchema <- NULL
# Start connection
conn <- DatabaseConnector::connect(connectionDetails)
# Save table FP to file, so it can be parsed in Python.
tablepaths <- c(results_database_schema, cohortTable)
write.table(tablepaths, 'tablepaths.txt', sep = ",", row.names=FALSE, col.names=FALSE)
use_python(PYTHON_PATH) # Python interpreter specified in parameters
# https://community.rstudio.com/t/rpytools-error-recurring-with-package-reticulate/66625
# If it does throw the rpytools error, it's just a runtime error that doesn't actually
# Inhibit the scripts. Just run the same lines twice and it fixes it...
sys <- import("sys", convert = TRUE) # Fixes run-time warning and error?
sys <- import("sys", convert = TRUE) # Fixes run-time warning and error?
py_run_file('testing_imports.py')
# Load the package
library(characterizationPaperPackage)
library(characterizationPaperPackage)
# Parameters [loaded from credentials.csv, which is not uploaded to Github!]
CREDENTIALS  <- 'C:\\Users\\tonys\\Documents\\Research\\csv\\credentials.csv' # login credentials
private.data = read.csv(CREDENTIALS, fileEncoding = 'UTF-8-BOM')
PYTHON_PATH  <- 'C:\\Users\\tonys\\AppData\\Local\\Programs\\Python\\Python39'
# PYTHON_PATH  <- 'C:\\Users\\admin_jhardi10\\AppData\\Local\\Programs\\Python\\Python39'
PACKAGE_PATH <- 'c:/Users/tonys/Research/characterizationPaperPackage/'
DB           <- private.data$db
# You do not have to change the below [but you can]
cdmDatabaseSchema    <- paste(DB, ".dbo", sep='')     # eg: "ohdsi_cumc_2021q1r2.dbo"
cohortDatabaseSchema <- paste(DB, ".results", sep='') # eg: "ohdsi_cumc_2021q1r2.results"
vocabularyDatabaseSchema <- cdmDatabaseSchema
cohortTable <- "cohort_characterization"              # this is the name of the output table for the cohorts
# Optional: specify where the temporary files will be created:
options(andromedaTempFolder = "D:\\andromedaTemp")
connectionDetails <- DatabaseConnector::createConnectionDetails(dbms = private.data$dbms,
server = private.data$server,
user = private.data$user,
password = private.data$password,
)
# For Oracle: define a schema that can be used to emulate temp tables:
oracleTempSchema <- NULL
# Start connection
conn <- DatabaseConnector::connect(connectionDetails)
# Instantiate cohorts:
pathToCsv <- system.file("settings", "CohortsToCreateFinal.csv", package = "characterizationPaperPackage")
cohortsToCreate <- readr::read_csv(pathToCsv, col_types = readr::cols())
#
# Save table FP to file, so it can be parsed in Python.
tablepaths <- c(results_database_schema, cohortTable)
write.table(tablepaths, 'tablepaths.txt', sep = ",", row.names=FALSE, col.names=FALSE)
use_python(PYTHON_PATH) # Python interpreter specified in parameters
# https://community.rstudio.com/t/rpytools-error-recurring-with-package-reticulate/66625
# If it does throw the rpytools error, it's just a runtime error that doesn't actually
# Inhibit the scripts. Just run the same lines twice and it fixes it...
sys <- import("sys", convert = TRUE) # Fixes run-time warning and error?
sys <- import("sys", convert = TRUE) # Fixes run-time warning and error?
py_run_file('testing_imports.py')
